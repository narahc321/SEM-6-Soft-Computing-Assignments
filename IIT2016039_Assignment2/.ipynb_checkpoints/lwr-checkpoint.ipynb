{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      price  bias   lotsize  bedrooms   bathrms   stories  driveway   recroom  \\\n",
      "0 -0.978239   1.0  0.322732  0.047192 -0.568973  0.221501  0.404819 -0.464371   \n",
      "1 -1.109312   1.0 -0.530526 -1.308947 -0.568973 -0.930304  0.404819 -0.464371   \n",
      "2 -0.697368   1.0 -0.964074  0.047192 -0.568973 -0.930304  0.404819 -0.464371   \n",
      "3 -0.285425   1.0  0.691709  0.047192 -0.568973  0.221501  0.404819  2.149509   \n",
      "4 -0.266700   1.0  0.557955 -1.308947 -0.568973 -0.930304  0.404819 -0.464371   \n",
      "\n",
      "   fullbase     gashw    airco  garagepl  prefarea  \n",
      "0  1.362070 -0.218853 -0.68041  0.357239 -0.552865  \n",
      "1 -0.732832 -0.218853 -0.68041 -0.803788 -0.552865  \n",
      "2 -0.732832 -0.218853 -0.68041 -0.803788 -0.552865  \n",
      "3 -0.732832 -0.218853 -0.68041 -0.803788 -0.552865  \n",
      "4 -0.732832 -0.218853 -0.68041 -0.803788 -0.552865  \n",
      "   bias   lotsize  bedrooms   bathrms   stories  driveway   recroom  fullbase  \\\n",
      "0   1.0  0.322732  0.047192 -0.568973  0.221501  0.404819 -0.464371  1.362070   \n",
      "1   1.0 -0.530526 -1.308947 -0.568973 -0.930304  0.404819 -0.464371 -0.732832   \n",
      "2   1.0 -0.964074  0.047192 -0.568973 -0.930304  0.404819 -0.464371 -0.732832   \n",
      "3   1.0  0.691709  0.047192 -0.568973  0.221501  0.404819  2.149509 -0.732832   \n",
      "4   1.0  0.557955 -1.308947 -0.568973 -0.930304  0.404819 -0.464371 -0.732832   \n",
      "\n",
      "      gashw    airco  garagepl  prefarea  \n",
      "0 -0.218853 -0.68041  0.357239 -0.552865  \n",
      "1 -0.218853 -0.68041 -0.803788 -0.552865  \n",
      "2 -0.218853 -0.68041 -0.803788 -0.552865  \n",
      "3 -0.218853 -0.68041 -0.803788 -0.552865  \n",
      "4 -0.218853 -0.68041 -0.803788 -0.552865  \n",
      "      price\n",
      "0 -0.978239\n",
      "1 -1.109312\n",
      "2 -0.697368\n",
      "3 -0.285425\n",
      "4 -0.266700\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"Housing Price data set.csv\")\n",
    "for i in data.columns:\n",
    "    x={'yes':1,'no':0}\n",
    "    if data[i].dtype=='object':\n",
    "#         data=data.drop([i],axis=1)\n",
    "        data[i]=data[i].map(x)\n",
    "data=data.drop(['Unnamed: 0'],axis=1)\n",
    "# data = shuffle(data) \n",
    "price_mean, price_std = data.mean()[0], data.std()[0]\n",
    "data  = (data - data.mean())/data.std()\n",
    "data.insert(loc=1,column='bias',value=np.ones([data.shape[0],1]))\n",
    "print(data.head())\n",
    "inp = data.iloc[:,1:]\n",
    "outp = data.iloc[:,:1]\n",
    "# train_data, train_label = inp.iloc[:(int)(inp.shape[0]*.75),:] , outp.iloc[:(int)(inp.shape[0]*.75),:] \n",
    "# test_data, test_label = inp.iloc[(int)(inp.shape[0]*.75):,:] , outp.iloc[(int)(inp.shape[0]*.75):,:] \n",
    "train_data, train_label = inp, outp\n",
    "test_data, test_label = inp, outp\n",
    "print(inp.head())\n",
    "print(outp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tau_norm_weights(x, x0, tau):\n",
    "    weg = np.exp(np.sum((x-x0)*(x-x0), axis=1)/(-2*tau*tau))\n",
    "    weg = np.diag(weg)\n",
    "    return np.array(weg)\n",
    "\n",
    "def error_comp(H,Y):\n",
    "    return abs((Y - H)/ Y)\n",
    "\n",
    "def norm(X, Y, X0,tau):\n",
    "    weg = tau_norm_weights(X, X0, tau)\n",
    "    XWEG = X.T.dot(weg)\n",
    "    XY_Li=np.linalg.inv(np.dot(XWEG,X))\n",
    "    XY=np.dot(XWEG,Y)\n",
    "    W=np.dot(XY_Li,XY)\n",
    "    return W\n",
    "\n",
    "for tau in range(1,1001,100):\n",
    "    X = np.array(train_data)\n",
    "    Y = np.array(train_label)\n",
    "    tot = 0.0\n",
    "    for x0 in range(len(X)): \n",
    "        W = norm(X, Y, X[x0],tau)\n",
    "        prediction = np.array(X[x0].dot(W))\n",
    "        prediction = prediction * price_std + price_mean\n",
    "        YY = Y[x0] * price_std + price_mean\n",
    "        err = error_comp(prediction, YY)\n",
    "        tot += err\n",
    "    print(\"tau : \",tau,\"=> accuracy : \",(1-(tot/len(X))[0])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tau :  1 => accuracy :  [83.12141168]\n",
      "tau :  101 => accuracy :  [82.33596842]\n",
      "tau :  201 => accuracy :  [82.33516515]\n",
      "tau :  301 => accuracy :  [82.33501481]\n",
      "tau :  401 => accuracy :  [82.33496199]\n",
      "tau :  501 => accuracy :  [82.33493749]\n",
      "tau :  601 => accuracy :  [82.33492417]\n",
      "tau :  701 => accuracy :  [82.33491612]\n",
      "tau :  801 => accuracy :  [82.3349109]\n",
      "tau :  901 => accuracy :  [82.33490732]\n"
     ]
    }
   ],
   "source": [
    "def tau_norm_weights(x, x0, tau):\n",
    "    weg = np.exp(np.sum((x-x0)*(x-x0), axis=1)/(-2*tau*tau))\n",
    "    weg = np.diag(weg)\n",
    "    return np.array(weg)\n",
    "\n",
    "def error_comp(H,Y):\n",
    "    return abs((Y - H)/ Y)\n",
    "\n",
    "def cost(H,Y):\n",
    "    return ((1/(2*len(Y)))*(sum((H-Y)*(H-Y))))[0]\n",
    "\n",
    "\n",
    "def gradient_descent(X,Y,W,l,learning_rate,epochs,X0,tau):\n",
    "    weg = tau_norm_weights(X, X0, tau)\n",
    "    act_Y = Y.reshape(len(Y))\n",
    "#     cos = []\n",
    "    for i in range(epochs):\n",
    "        h_x=X.dot(W)\n",
    "#         cos.append(cost(h_x,Y))\n",
    "        W = W - (1/len(Y))*learning_rate*((X.T.dot(weg)).dot(h_x - Y))\n",
    "    return W, #cos\n",
    "\n",
    "for tau in range(1,1001,100):\n",
    "    X = np.array(train_data)\n",
    "    Y = np.array(train_label)\n",
    "    tot = 0.0\n",
    "    learning_rate = 1e-1\n",
    "    epochs = 100\n",
    "    for x0 in range(len(X)): \n",
    "#         W = norm(X, Y, X[x0],tau)\n",
    "        W = np.zeros([X.shape[1],1])\n",
    "        W =gradient_descent(X,Y,W,0,learning_rate,epochs,X[x0],tau)\n",
    "        prediction = np.array(X[x0].dot(W))\n",
    "        prediction = prediction * price_std + price_mean\n",
    "        YY = Y[x0] * price_std + price_mean\n",
    "        err = error_comp(prediction, YY)\n",
    "        tot += err\n",
    "    print(\"tau : \",tau,\"=> accuracy : \",(1-(tot/len(X))[0])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.array(train_data)\n",
    "# Y = np.array(train_label)\n",
    "# print(X.shape)\n",
    "# print(Y.shape)\n",
    "# learning_rate = 1e-1\n",
    "# epochs = 1000\n",
    "# W = norm(X,Y)\n",
    "# cos = cost(X.dot(W),Y)\n",
    "# print(cos)\n",
    "# ne_cos = [cos for i in range(epochs)]\n",
    "\n",
    "\n",
    "# W = np.zeros([X.shape[1],1])\n",
    "# W, l_cos =gradient_descent(X,Y,W,0,learning_rate,epochs)\n",
    "# # print(W)\n",
    "# print(l_cos[-1])\n",
    "\n",
    "# x = [i for i in range(epochs)]\n",
    "# plt.plot(x,l_cos,'-r')\n",
    "# plt.plot(x,ne_cos,'-b')\n",
    "# plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
