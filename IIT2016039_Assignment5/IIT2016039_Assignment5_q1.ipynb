{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,precision_recall_fscore_support\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import PorterStemmer , WordNetLemmatizer\n",
    "from sklearn.utils import shuffle\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4438</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2666</th>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       v1\n",
       "4438  ham\n",
       "125   ham\n",
       "547   ham\n",
       "2591  ham\n",
       "2666  ham"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"spam.csv\", encoding='latin-1')\n",
    "data.head()\n",
    "data = shuffle(data)\n",
    "inp = data.iloc[:,1:2]\n",
    "outp = data.iloc[:,0:1]\n",
    "split = .8\n",
    "train_data, train_label = inp.iloc[:(int)(inp.shape[0]*split),:] , outp.iloc[:(int)(inp.shape[0]*split),:] \n",
    "test_data, test_label = inp.iloc[(int)(inp.shape[0]*split):,:] , outp.iloc[(int)(inp.shape[0]*split):,:]\n",
    "\n",
    "# train_data, train_label = inp, outp\n",
    "# test_data, test_label = inp, outp\n",
    "\n",
    "outp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemma = WordNetLemmatizer()\n",
    "ps = PorterStemmer()\n",
    "def preprocess_data(mess):\n",
    "#     return mess\n",
    "    mess = mess.lower()\n",
    "    nostop = \" \".join([i for i in mess.split() if i not in stopwords.words('english')])\n",
    "    nonum = [char for char in nostop if char not in ['0','1','2','3','4','5','6','7','8','9']]\n",
    "    nopunc =[char for char in nonum if char not in string.punctuation]\n",
    "    nopunc=''.join(nopunc)\n",
    "    stem = \" \".join(ps.stem(word) for word in nopunc.split())\n",
    "#     lem = \" \".join(lemma.lemmatize(word) for word in nopunc.split())\n",
    "    return stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4457, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Narahc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4438</th>\n",
       "      <td>want grasp pretti booti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>good stuff do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>sorri took long omw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>still work go onit small hous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2666</th>\n",
       "      <td>nice day and impress sensibl went home earli f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     v2\n",
       "4438                            want grasp pretti booti\n",
       "125                                       good stuff do\n",
       "547                                 sorri took long omw\n",
       "2591                      still work go onit small hous\n",
       "2666  nice day and impress sensibl went home earli f..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['v2'] = train_data['v2'].apply(preprocess_data)\n",
    "print(train_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     v2\n",
      "4438                            want grasp pretti booti\n",
      "125                                       good stuff do\n",
      "547                                 sorri took long omw\n",
      "2591                      still work go onit small hous\n",
      "2666  nice day and impress sensibl went home earli f...\n",
      "Ham : 3860\n",
      "Spam : 597\n",
      "Total : 4457\n"
     ]
    }
   ],
   "source": [
    "print(inp.head())\n",
    "nham = (train_label.v1 == 'ham').sum()\n",
    "nspam = (train_label.v1 == 'spam').sum()\n",
    "ntot = train_label.shape[0]\n",
    "print(\"Ham :\", nham)\n",
    "print(\"Spam :\", nspam)\n",
    "print(\"Total :\", ntot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "597\n",
      "3860\n",
      "39229\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(train_data['v2'])\n",
    "\n",
    "spam_ar = train_data[(train_label.v1 == 'spam')] \n",
    "ham_ar = train_data[(train_label.v1 == 'ham')]\n",
    "\n",
    "spam_vec = vectorizer.transform(spam_ar['v2'])\n",
    "ham_vec = vectorizer.transform(ham_ar['v2'])\n",
    "spam_freq = np.array(spam_vec.sum(axis=0))\n",
    "ham_freq = np.array(ham_vec.sum(axis=0))\n",
    "\n",
    "no_spam = len(spam_ar)\n",
    "no_ham = len(ham_ar)\n",
    "\n",
    "spam_freq = spam_freq.reshape(spam_freq.shape[1])\n",
    "ham_freq = ham_freq.reshape(ham_freq.shape[1])\n",
    "tot_freq = spam_freq + ham_freq\n",
    "\n",
    "spam_words = spam_vec.sum() \n",
    "ham_words = ham_vec.sum()\n",
    "tot_words = spam_words + ham_words\n",
    "\n",
    "print(len(spam_ar))\n",
    "print(len(ham_ar))\n",
    "print(tot_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(predis):\n",
    "    predis = preprocess_data(predis)\n",
    "    spam_num = 1.00\n",
    "    ham_num = 1.00\n",
    "    for word in predis.split():\n",
    "        \n",
    "        fspam = 0\n",
    "        fham = 0\n",
    "        if word in vectorizer.vocabulary_:\n",
    "            fspam = spam_freq[vectorizer.vocabulary_[word]]\n",
    "            fham = ham_freq[vectorizer.vocabulary_[word]]\n",
    "\n",
    "        spam_num *= ((fspam +1) / (spam_words + len(vectorizer.vocabulary_)))\n",
    "        ham_num *= ((fham +1) / (ham_words + len(vectorizer.vocabulary_)))\n",
    "\n",
    "    spam_num = (spam_num * ((no_spam)/ ( no_spam + no_ham)))\n",
    "    ham_num = (ham_num * ((no_ham) / ( no_spam + no_ham)))\n",
    "    spamm = spam_num / (spam_num + ham_num)\n",
    "    hamm = ham_num / (spam_num + ham_num)\n",
    "    if spamm >= hamm:\n",
    "        return \"spam\"\n",
    "    return \"ham\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : [[949  12]\n",
      " [ 16 138]]\n",
      "ACCURACY : 0.9783978397839784\n",
      "(array([0.98341969, 0.92      ]), array([0.98751301, 0.8961039 ]), array([0.9854621 , 0.90789474]), array([961, 154], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "actual =[]\n",
    "prediction =[]\n",
    "# test_data['v2'] = test_data['v2'].apply(preprocess_data)\n",
    "test_data.head()\n",
    "for i, row in test_data.iterrows():\n",
    "    actual.append(predict(test_data['v2'][i]))\n",
    "    prediction.append(test_label['v1'][i])\n",
    "M = confusion_matrix(actual,prediction)\n",
    "print(\"Confusion Matrix :\", M)\n",
    "print(\"ACCURACY :\",(M[0][0]+M[1][1])/((M[0][0]+M[0][1] + M[0][1]+M[1][1])))\n",
    "print(precision_recall_fscore_support(actual,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\",I am hot n horny and willing I live local to you - text a reply to hear strt back from me 150p per msg Netcollex LtdHelpDesk: 02085076972 reply Stop to end\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
